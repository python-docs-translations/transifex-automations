# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2001-2025, Python Software Foundation
# This file is distributed under the same license as the Python package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
# Translators:
# Rafael Fontenelle <rffontenelle@gmail.com>, 2024
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Python 3.11\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-01-03 15:28+0000\n"
"PO-Revision-Date: 2023-05-24 02:21+0000\n"
"Last-Translator: Rafael Fontenelle <rffontenelle@gmail.com>, 2024\n"
"Language-Team: Russian (https://app.transifex.com/python-doc/teams/5390/"
"ru/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: ru\n"
"Plural-Forms: nplurals=4; plural=(n%10==1 && n%100!=11 ? 0 : n%10>=2 && "
"n%10<=4 && (n%100<12 || n%100>14) ? 1 : n%10==0 || (n%10>=5 && n%10<=9) || "
"(n%100>=11 && n%100<=14)? 2 : 3);\n"

#: ../../library/urllib.robotparser.rst:2
msgid ":mod:`urllib.robotparser` ---  Parser for robots.txt"
msgstr ""

#: ../../library/urllib.robotparser.rst:10
msgid "**Source code:** :source:`Lib/urllib/robotparser.py`"
msgstr "**Исходный код:** :source:`Lib/urllib/robotparser.py`"

#: ../../library/urllib.robotparser.rst:20
msgid ""
"This module provides a single class, :class:`RobotFileParser`, which answers "
"questions about whether or not a particular user agent can fetch a URL on "
"the web site that published the :file:`robots.txt` file.  For more details "
"on the structure of :file:`robots.txt` files, see http://www.robotstxt.org/"
"orig.html."
msgstr ""
"This module provides a single class, :class:`RobotFileParser`, which answers "
"questions about whether or not a particular user agent can fetch a URL on "
"the web site that published the :file:`robots.txt` file. For more details on "
"the structure of :file:`robots.txt` files, see http://www.robotstxt.org/orig."
"html."

#: ../../library/urllib.robotparser.rst:28
msgid ""
"This class provides methods to read, parse and answer questions about the :"
"file:`robots.txt` file at *url*."
msgstr ""
"Этот класс предоставляет методы для чтения, анализа и ответа на вопросы о "
"файле :file:`robots.txt` по адресу *url*."

#: ../../library/urllib.robotparser.rst:33
msgid "Sets the URL referring to a :file:`robots.txt` file."
msgstr "Устанавливает URL-адрес, ссылающийся на файл :file:`robots.txt`."

#: ../../library/urllib.robotparser.rst:37
msgid "Reads the :file:`robots.txt` URL and feeds it to the parser."
msgstr "Считывает URL-адрес :file:`robots.txt` и передает его анализатору."

#: ../../library/urllib.robotparser.rst:41
msgid "Parses the lines argument."
msgstr "Анализирует аргумент строки."

#: ../../library/urllib.robotparser.rst:45
msgid ""
"Returns ``True`` if the *useragent* is allowed to fetch the *url* according "
"to the rules contained in the parsed :file:`robots.txt` file."
msgstr ""
"Возвращает ``True``, если *useragent* разрешено получать *url* в "
"соответствии с правилами, содержащимися в анализируемом файле :file:`robots."
"txt`."

#: ../../library/urllib.robotparser.rst:51
msgid ""
"Returns the time the ``robots.txt`` file was last fetched.  This is useful "
"for long-running web spiders that need to check for new ``robots.txt`` files "
"periodically."
msgstr ""
"Возвращает время последнего получения файла robots.txt. Это полезно для "
"долго работающих веб-пауков, которым необходимо периодически проверять "
"наличие новых файлов robots.txt."

#: ../../library/urllib.robotparser.rst:57
msgid ""
"Sets the time the ``robots.txt`` file was last fetched to the current time."
msgstr ""
"Устанавливает время последнего получения файла robots.txt на текущее время."

#: ../../library/urllib.robotparser.rst:62
msgid ""
"Returns the value of the ``Crawl-delay`` parameter from ``robots.txt`` for "
"the *useragent* in question.  If there is no such parameter or it doesn't "
"apply to the *useragent* specified or the ``robots.txt`` entry for this "
"parameter has invalid syntax, return ``None``."
msgstr ""
"Возвращает значение параметра Crawl-delay из robots.txt для рассматриваемого "
"*useragent*. Если такого параметра нет или он не применим к указанному "
"*useragent* или запись в robots.txt для этого параметра имеет неверный "
"синтаксис, верните None."

#: ../../library/urllib.robotparser.rst:71
msgid ""
"Returns the contents of the ``Request-rate`` parameter from ``robots.txt`` "
"as a :term:`named tuple` ``RequestRate(requests, seconds)``. If there is no "
"such parameter or it doesn't apply to the *useragent* specified or the "
"``robots.txt`` entry for this parameter has invalid syntax, return ``None``."
msgstr ""
"Возвращает содержимое параметра Request-rate из robots.txt в виде :term:"
"`именованного кортежа``RequestRate(requests, секунды)``. Если такого "
"параметра нет или он не применим к указанному *useragent* или запись в "
"robots.txt для этого параметра имеет неверный синтаксис, верните None."

#: ../../library/urllib.robotparser.rst:81
msgid ""
"Returns the contents of the ``Sitemap`` parameter from ``robots.txt`` in the "
"form of a :func:`list`. If there is no such parameter or the ``robots.txt`` "
"entry for this parameter has invalid syntax, return ``None``."
msgstr ""
"Возвращает содержимое параметра Sitemap из robots.txt в виде списка. Если "
"такого параметра нет или запись в robots.txt для этого параметра имеет "
"неверный синтаксис, верните None."

#: ../../library/urllib.robotparser.rst:89
msgid ""
"The following example demonstrates basic use of the :class:`RobotFileParser` "
"class::"
msgstr ""
"Следующий пример демонстрирует базовое использование класса :class:"
"`RobotFileParser`::"

#: ../../library/urllib.robotparser.rst:12
msgid "WWW"
msgstr "WWW"

#: ../../library/urllib.robotparser.rst:12
msgid "World Wide Web"
msgstr "Всемирная паутина"

#: ../../library/urllib.robotparser.rst:12
msgid "URL"
msgstr "URL"

#: ../../library/urllib.robotparser.rst:12
msgid "robots.txt"
msgstr "robots.txt"
